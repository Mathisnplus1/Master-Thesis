{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce0e9e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0275f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447b9616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameter\n",
    "batch_size=128\n",
    "\n",
    "# Network's initial architecture\n",
    "num_inputs = 28*28\n",
    "num_hidden = 10\n",
    "num_outputs = 10\n",
    "\n",
    "# Network's final architecture\n",
    "num_hidden_target = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d3056df",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "data_path = path + \"\\\\data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605449f1",
   "metadata": {},
   "source": [
    "## Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f76de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "def get_MNIST_loaders(path, class_names, batch_size) :\n",
    "\n",
    "    # load MNIST \n",
    "    mnist_train = datasets.MNIST(root=path, train=True, download=False, transform=transform)\n",
    "    mnist_test = datasets.MNIST(root=path, train=False, download=False, transform=transform)\n",
    "\n",
    "\n",
    "    # create a mask to filter indices for each label\n",
    "    train_mask = torch.tensor([label in class_names for label in mnist_train.targets])\n",
    "    test_mask = torch.tensor([label in class_names for label in mnist_test.targets])\n",
    "\n",
    "    # Create Subset datasets for train, validation, and test\n",
    "    train_dataset = Subset(mnist_train, torch.where(train_mask)[0])\n",
    "    test_dataset = Subset(mnist_test, torch.where(test_mask)[0])\n",
    "\n",
    "    # split train into train & validation\n",
    "    train_size = int(0.7 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7105969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_MNIST_loaders(data_path, [i for i in range(10)], batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d95d8d",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a647ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN (nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_inputs,num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.fc3 = nn.Linear(num_hidden, num_outputs)\n",
    "        \n",
    "        self.activation = torch.sigmoid ## nn.ReLU()\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def add_neurons (self, fc1_weight_grad, fc1_bias_grad, fc2_weight_grad, num_neurons, device) :\n",
    "        # Add weights and biases to the layer of interest (fc1)\n",
    "        num_in_1, num_out_1 = self.fc2.in_features, self.fc2.out_features\n",
    "        num_in_2, num_out_2 = self.fc3.in_features, self.fc3.out_features\n",
    "\n",
    "        # PRE-LAYER\n",
    "        # Set parameters\n",
    "        self.fc2.weight = nn.Parameter(torch.cat((self.fc2.weight,torch.zeros(num_neurons, num_in_1).to(device))))\n",
    "        self.fc2.bias = nn.Parameter(torch.cat((self.fc2.bias, torch.zeros(num_neurons).to(device))))\n",
    "\n",
    "        # Set gradients\n",
    "        self.fc2.weight.grad = nn.Parameter(torch.cat((fc1_weight_grad,torch.zeros(num_neurons, num_in_1).to(device)), dim=0))\n",
    "        self.fc2.bias.grad = nn.Parameter(torch.cat((fc1_bias_grad, torch.zeros(num_neurons).to(device)), dim=0))\n",
    "\n",
    "        # POST-LAYER\n",
    "        # Set parameters\n",
    "        self.fc3.weight = nn.Parameter(torch.cat((self.fc3.weight, torch.zeros(num_out_2,num_neurons).to(device)), dim=1))\n",
    "\n",
    "        # Set gradients\n",
    "        self.fc3.weight.grad = torch.cat((fc2_weight_grad, torch.zeros(num_out_2, num_neurons).to(device)), dim=1)\n",
    "        print((self.fc2.weight.grad != 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad61c1f",
   "metadata": {},
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0b54e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_parameters(model) :\n",
    "    num_params = 0\n",
    "    for param_name, param in model.named_parameters():\n",
    "        num_param = torch.numel(param)\n",
    "        print(param_name, \":\", num_param)\n",
    "        num_params += num_param\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a38ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_accuracy(model, data, targets, batch_size):\n",
    "    output = model(data.view(batch_size, -1))\n",
    "    idx = output.argmax(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    return round(acc*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2a81935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, data, targets, loss, loss_name, batch_size) :\n",
    "    if loss_name == \"CE\":\n",
    "        y = model(data.view(batch_size, -1))\n",
    "        loss_val = loss(y, targets)\n",
    "    else :\n",
    "        y = model(data.view(batch_size, -1))\n",
    "        one_hot_targets = nn.functional.one_hot(targets, num_classes=10).to(y.dtype)\n",
    "        loss_val = loss(y, one_hot_targets)\n",
    "    return y, loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6f60925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_val (model, loss, loss_name, val_loader, val_loss_hist, val_acc_hist, epoch, batch_size, device, print_shit=False) :\n",
    "    model.eval()\n",
    "    val_data, val_targets = next(iter(val_loader))\n",
    "    val_data = val_data.to(device)\n",
    "    val_targets = val_targets.to(device)\n",
    "    \n",
    "    # Forward path\n",
    "    y, val_loss_val = compute_loss(model, val_data, val_targets, loss, loss_name, batch_size)\n",
    "    val_loss_hist.append(val_loss_val.item())\n",
    "    \n",
    "    # ACCURACY\n",
    "    if print_shit :\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        # print(f\"Train Set Loss: {train_loss_hist[epoch]:.2f}\")\n",
    "        print(f\"Val Set Loss: {val_loss_hist[epoch]:.2f}\")\n",
    "        print(\"\\n\")\n",
    "    val_acc_hist.append(get_batch_accuracy(model, val_data, val_targets, batch_size))\n",
    "    \n",
    "    \n",
    "    return val_loss_hist, val_acc_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a0f22",
   "metadata": {},
   "source": [
    "GradMax offers a way to initialize the added neurons :\n",
    "- $W_l^{new}$ set to $0$ (cf hypothesis between eq (8) and (9)) ♠\n",
    "- $\\frac{\\partial L}{\\partial W_{l}^{new}}$ set to $W_{l+1}^{new,T} \\mathbb{E}_D\\left[\\frac{\\partial L}{\\partial z_{l+1}}h_{l-1}^T\\right]$ even though (9) suggests $W_{l+1}^{new,T} \\frac{\\partial L}{\\partial z_{l+1}}h_{l-1}^T$ ♠\n",
    "- $B_l^{new}$ set to 0 (not mentioned in the paper, \"zeros or ones\" according to layers.py file in the code) ♠\n",
    "- $\\frac{\\partial L}{\\partial B_{l}^{new}}$ set to 0 (not mentioned in the paper) ♠\n",
    "- $W_{l+1}^{new}$ set as the top $k$ left-singular vectors of the matrix $\\mathbb{E}_D\\left[\\frac{\\partial L}{\\partial z_{l+1}}h_{l-1}^T\\right]$ and scaling them by $\\frac{c}{||(\\sigma_1,...,\\sigma_k)||}$ (where $\\sigma_i$\n",
    "is the $i$-th largest singular value) ♠\n",
    "- $\\frac{\\partial L}{\\partial W_{l+1}^{new}}$ set to $0$ (eq (10)) ♠"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6dc5d1",
   "metadata": {},
   "source": [
    "On veut calculer $\\mathbb{E}_D\\left[\\frac{\\partial L}{\\partial z_{l+1}}h_{l-1}^T\\right]$.\n",
    "Détail :\n",
    "- $\\frac{\\partial L}{\\partial z_{l+1}}$ : $[10,1]$ ou $[num_{hidden},1]$ (c'est le gradient calculé dans le layer suivant)\n",
    "- $h_{l-1}^T$ : $[1,784]$ (c'est simplement l'input x)\n",
    "Donc en fait, on veut juste la \n",
    "\n",
    "On sait calculer obtenir ces deux quantités, il suffit de faire la moyenne sur les données vue depuis le dernier ajout d'un neurone (tout le training set si on ajoute des neurones à la fin de chaque epoch, ou tout le batch si on ajoute des neurones à la fin de batchs)\n",
    "\n",
    "Impémentation :\n",
    "- On a besoin de savoir pendant quel layer on veut grow dans la training loop, pour savoir quel gradient on doit stocker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10d275f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neurons (fc1, fc2, num_neurons, grow_matrix, c, device) :\n",
    "    # Add weights and biases to the layer of interest (fc1)\n",
    "    num_in_1, num_out_1 = fc1.in_features, fc1.out_features\n",
    "    new_fc1 = nn.Linear(in_features=num_in_1, out_features=num_out_1 + num_neurons).to(device)\n",
    "    \n",
    "    # Solve optimization problem (11)\n",
    "    u, s, vh = svds(grow_matrix.cpu().detach().numpy(), k=num_neurons, return_singular_vectors=True)\n",
    "    #print(fc1, (grow_matrix == 0).sum())\n",
    "    #print(\"u :\", u.shape)\n",
    "    #print(\"vh :\", vh.shape)\n",
    "    eigenvals, eigenvecs = (s**2), u[::-1]\n",
    "    #print(s)\n",
    "    scaler = c / np.sqrt(eigenvals.sum())\n",
    "    scaler = 1\n",
    "    #print(scaler)\n",
    "    new_weights_next_layer = (1/scaler)*torch.tensor(eigenvecs[:, :num_neurons].copy()).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Set parameters\n",
    "        new_fc1.weight[:num_out_1, :] = fc1.weight\n",
    "        new_fc1.bias[:num_out_1] = fc1.bias\n",
    "        new_fc1.weight[num_out_1:, :] = torch.zeros(num_neurons, num_in_1)\n",
    "        new_fc1.bias[num_out_1:] = torch.zeros(num_neurons)\n",
    "        # Set gradients\n",
    "        #print(\"W_l+1^new transpose :\", new_weights_next_layer.t().shape)\n",
    "        #print(\"grow_matrix :\", grow_matrix.shape)\n",
    "        #print(\"new_grad :\", fc1.weight.grad.shape)\n",
    "        # new_fc1.weight.grad =  # torch.cat((fc1.weight.grad, add_weight_grads_1), dim=0)\n",
    "        \n",
    "        # add_weight_grads_1 = torch.mm(new_weights_next_layer.t(), grow_matrix).to(device)\n",
    "        add_weight_grads_1 = torch.zeros(num_neurons, num_in_1).to(device)\n",
    "        new_fc1.weight.grad = torch.cat((fc1.weight.grad,add_weight_grads_1), dim=0)\n",
    "        \n",
    "        add_bias_grad_1 = torch.zeros(num_neurons).to(device)\n",
    "        new_fc1.bias.grad = torch.cat((fc1.bias.grad, add_bias_grad_1), dim=0)\n",
    "        \n",
    "    # Add weights to the following layer (fc2) so it matches fc1 size \n",
    "    num_in_2, num_out_2 = fc2.in_features, fc2.out_features\n",
    "    new_fc2 = nn.Linear(in_features=num_in_2 + num_neurons, out_features=num_out_2).to(device)\n",
    "    with torch.no_grad():\n",
    "        new_fc2.weight[:, :num_in_2] = fc2.weight\n",
    "        #print(\"new_weights :\", new_fc2.weight[:, num_in_2:].shape)\n",
    "        #print(\"potential :\", new_weights_next_layer.shape)\n",
    "        new_weights_next_layer = torch.zeros(num_out_2,num_neurons)\n",
    "        new_fc2.weight[:, num_in_2:] = new_weights_next_layer # torch.zeros(num_out_2,num_neurons)\n",
    "        # Set gradients\n",
    "        add_weight_grads_2 = torch.zeros(num_out_2, num_neurons).to(device)\n",
    "        new_fc2.weight.grad = torch.cat((fc2.weight.grad, add_weight_grads_2), dim=1)\n",
    "    \n",
    "    return new_fc1, new_fc2.to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e0e7b57",
   "metadata": {},
   "source": [
    "def add_neurons (fc1, fc2, num_neurons, grow_matrix, c, device) :\n",
    "        # Add weights and biases to the layer of interest (fc1)\n",
    "        num_in_1, num_out_1 = fc1.in_features, fc1.out_features\n",
    "        new_fc1 = nn.Linear(in_features=num_in_1, out_features=num_out_1 + num_neurons).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Set parameters\n",
    "            new_fc1.weight[:num_out_1, :] = fc1.weight\n",
    "            new_fc1.bias[:num_out_1] = fc1.bias\n",
    "            new_fc1.weight[num_out_1:, :] = fc1.weight.mean() * torch.ones(num_neurons, num_in_1).to(device)\n",
    "            new_fc1.bias[num_out_1:] = torch.zeros(num_neurons)\n",
    "            \n",
    "            # Set gradients\n",
    "            add_weight_grads_1 = fc1.weight.grad.mean() * torch.ones(num_neurons, num_in_1).to(device)\n",
    "            new_fc1.weight.grad = torch.cat((fc1.weight.grad,add_weight_grads_1), dim=0)\n",
    "            add_bias_grad_1 = torch.zeros(num_neurons).to(device)\n",
    "            new_fc1.bias.grad = torch.cat((fc1.bias.grad, add_bias_grad_1), dim=0)\n",
    "\n",
    "        # Add weights to the following layer (fc2) so it matches fc1 size \n",
    "        num_in_2, num_out_2 = fc2.in_features, fc2.out_features\n",
    "        new_fc2 = nn.Linear(in_features=num_in_2 + num_neurons, out_features=num_out_2).to(device)\n",
    "        with torch.no_grad():\n",
    "            # Set parameters\n",
    "            new_fc2.weight[:, :num_in_2] = fc2.weight\n",
    "            new_fc2.weight[:, num_in_2:] = fc2.weight.mean() * torch.ones(num_out_2,num_neurons).to(device)\n",
    "            new_fc2.bias = fc2.bias\n",
    "            \n",
    "            # Set gradients\n",
    "            add_weight_grads_2 = fc2.weight.grad.mean() * torch.ones(num_out_2, num_neurons).to(device)\n",
    "            new_fc2.weight.grad = torch.cat((fc2.weight.grad, add_weight_grads_2), dim=1)\n",
    "            new_fc2.bias.grad = fc2.bias.grad\n",
    "\n",
    "        return new_fc1, new_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5619882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_hooks(model, pre_layer, post_layer):\n",
    "    activation = []\n",
    "    grad = []\n",
    "\n",
    "    def forward_hook(module, x, y):\n",
    "        activation.append(y)\n",
    "    def backward_hook(module, grad_input, grad_output) :\n",
    "        grad.append(grad_output)\n",
    "    \n",
    "    forward_hook_handle = None\n",
    "    if pre_layer :\n",
    "        forward_hook_handle = pre_layer.register_forward_hook(forward_hook)\n",
    "        \n",
    "    backward_hook_handle = post_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "    return activation, grad, forward_hook_handle, backward_hook_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d36f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (model, growth_schedule, loss, loss_name, optimizer, train_loader, val_loader, \n",
    "           num_epochs, batch_size, device, c = 1, print_num_params = 0) :\n",
    "    train_loss_hist, val_loss_hist = [], []\n",
    "    train_acc_hist, val_acc_hist = [], []\n",
    "    \n",
    "    # Epoch training loop\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        \n",
    "        train_batch = iter(train_loader)\n",
    "        loss_epoch = 0\n",
    "        batch_index = 0\n",
    "        \n",
    "        # Batch training loop\n",
    "        for i, (data, targets) in enumerate(train_batch):\n",
    "            # Get data from the batch\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            \n",
    "            # Initialize the matrix on which we will perform GradMax\n",
    "            if (growth_schedule is not None) and (batch_index%50 == 0) :\n",
    "            \n",
    "                \n",
    "                # Remove previous hooks in case they are some\n",
    "                for h in hooks_list :\n",
    "                    h.remove()\n",
    "                \n",
    "                # Print the number of parameters\n",
    "                if print_num_params :\n",
    "                    count_all_parameters(model)\n",
    "                \n",
    "                layer_name, num_neurons = next(growth_schedule)\n",
    "                if layer_name == \"fc1\" :\n",
    "                    matrix_to_SVD = torch.zeros(model.fc2.out_features, model.fc1.in_features).to(device)\n",
    "                elif layer_name == \"fc2\" :\n",
    "                    matrix_to_SVD = torch.zeros(model.fc3.out_features, model.fc2.in_features).to(device)\n",
    "                    #print(\"matrix_to_SVD :\", matrix_to_SVD.shape)\n",
    "\n",
    "            # forward pass\n",
    "            model.train()\n",
    "            \n",
    "            # Get the gradient of the layer after the one we grow, for GradMax computation\n",
    "            if (growth_schedule is not None) : #and (batch_index%50 == 0) :\n",
    "                if layer_name == \"fc1\" :\n",
    "                    \n",
    "                    h = data.view(batch_size, -1)\n",
    "                    # register hooks\n",
    "                    _, grad, _, backward_hook_handle = register_hooks(model, None, model.fc2)\n",
    "                    hooks_list.append(backward_hook_handle)\n",
    "                    \n",
    "                    # Forward path\n",
    "                    y, loss_val = compute_loss(model, data, targets, loss, loss_name, batch_size)\n",
    "                    \n",
    "                    # Gradient calculation + weight update\n",
    "                    #output_grad = torch.zeros(torch.Size([])).requires_grad_(True).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss_val.backward() # Pass output_grad\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # Compute the matrix to which we will apply SVD\n",
    "                    if batch_index%50 == 0 :\n",
    "                        #print(\"output_grad : \", output_grad)\n",
    "                        #print(\"grad shape :\", grad[0][0].t()[0])\n",
    "                        #print(\"h shape :\", h.shape)\n",
    "                        #print(\"h zeros :\", (h==0).sum())\n",
    "                        #print(\"matrix :\", matrix_to_SVD)\n",
    "                        pass\n",
    "                    #matrix_to_SVD += torch.mm(grad[0][0].t(),h) / batch_size\n",
    "                    \n",
    "                elif layer_name == \"fc2\" :\n",
    "                    # register hooks\n",
    "                    h, grad, forward_hook_handle, backward_hook_handle = register_hooks(model, model.fc1, model.fc3)\n",
    "                    hooks_list.append(forward_hook_handle)\n",
    "                    hooks_list.append(backward_hook_handle)\n",
    "                    \n",
    "                    # Forward path\n",
    "                    y, loss_val = compute_loss(model, data, targets, loss, loss_name, batch_size)\n",
    "                    \n",
    "                    # Gradient calculation + weight update\n",
    "                    #output_grad = torch.ones(torch.Size([])).requires_grad_(True)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss_val.backward() # Pass output_grad\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # Compute the matrix to which we will apply SVD\n",
    "                    if batch_index%50 == 0 :\n",
    "                        #print(\"output_grad : \", output_grad)\n",
    "                        #print(\"grad shape :\", grad[0][0].t()[0])\n",
    "                        #print(\"h shape :\", (h[0].shape))\n",
    "                        #print(\"h zeros :\", (h[0]==0).sum())\n",
    "                        #print(\"h :\", h[0][0])\n",
    "                        #print(\"matrix :\", matrix_to_SVD)\n",
    "                        #print(\"w_fc1 :\", model.fc2.weight[:,0])\n",
    "                        pass\n",
    "                    #matrix_to_SVD += torch.mm(grad[0][0].t(),h[0]) / batch_size\n",
    "            \n",
    "            else :\n",
    "                # Forward path\n",
    "                y, loss_val = compute_loss(model, data, targets, loss, loss_name, batch_size)\n",
    "                \n",
    "                # Gradient calculation + weight update\n",
    "                optimizer.zero_grad()\n",
    "                loss_val.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            loss_epoch += loss_val.item()\n",
    "            \n",
    "            \n",
    "            # Add neurons\n",
    "            if (growth_schedule is not None) and (batch_index%50 == 0) :\n",
    "                #with torch.no_grad():\n",
    "                    # Solve optimization problem (11)\n",
    "                    #print(\"Shape of matrix_to_SVD :\", matrix_to_SVD.shape)\n",
    "                    # matrix_to_SVD = matrix_to_SVD.t()\n",
    "\n",
    "                    #if layer_name == \"fc1\" :\n",
    "                    #    model.fc1, model.fc2 = add_neurons(model.fc1, model.fc2, num_neurons, matrix_to_SVD, c, device)\n",
    "                    #elif layer_name == \"fc2\" :\n",
    "                    #    model.fc2, model.fc3 = add_neurons(model.fc2, model.fc3, num_neurons, matrix_to_SVD, c, device)\n",
    "                    \n",
    "                    fc1_weight_grad = model.fc2.weight.grad\n",
    "                    fc1_bias_grad = model.fc2.bias.grad\n",
    "                    fc2_weight_grad = model.fc3.weight.grad\n",
    "                    model.add_neurons(fc1_weight_grad, fc1_bias_grad, fc2_weight_grad, num_neurons, device)\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, maximize=False)\n",
    "            \n",
    "            # Test set\n",
    "            if batch_index%50 == 49:\n",
    "                with torch.no_grad():\n",
    "                    # Train data\n",
    "                    # Store loss and acc histories for future plotting\n",
    "                    train_loss_hist.append(loss_epoch/len(train_loader))\n",
    "                    train_acc_hist.append(get_batch_accuracy(model, data, targets, batch_size))\n",
    "                    \n",
    "                    # Val data\n",
    "                    val_loss_hist, val_acc_hist = compute_val (model,\n",
    "                                                               loss,\n",
    "                                                               loss_name,\n",
    "                                                               val_loader, \n",
    "                                                               val_loss_hist, \n",
    "                                                               val_acc_hist,\n",
    "                                                               epoch,\n",
    "                                                               batch_size,\n",
    "                                                               device,\n",
    "                                                               print_shit=False)\n",
    "                    \n",
    "                    \n",
    "            batch_index += 1\n",
    "\n",
    "            if batch_index%50 == 0:\n",
    "                print(f'{batch_index} batches used in epoch {epoch}')\n",
    "\n",
    "        \n",
    "    output = [train_loss_hist, train_acc_hist, val_loss_hist, val_acc_hist]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc60767",
   "metadata": {},
   "source": [
    "## Train the target model for comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b09fecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = ANN(num_inputs, num_hidden_target, num_outputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "610d0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss() # nn.CrossEntropyLoss()\n",
    "loss_name = \"MSE\" # \"CE\"\n",
    "optimizer = torch.optim.Adam(target_model.parameters(), lr=5e-3, maximize=False)\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b81e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_schedule = None\n",
    "hooks_list= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9585593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 batches used in epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrowth_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [72], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, growth_schedule, loss, loss_name, optimizer, train_loader, val_loader, num_epochs, batch_size, device, c, print_num_params)\u001b[0m\n\u001b[0;32m     11\u001b[0m batch_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Batch training loop\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (data, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_batch):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Get data from the batch\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\users\\mathis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\users\\mathis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\users\\mathis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\users\\mathis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:397\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices: List[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[T_co]:\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;66;03m# add batched sampling support when parent dataset supports it.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;66;03m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m--> 397\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\users\\mathis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\users\\mathis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\users\\mathis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\users\\mathis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\users\\mathis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\mathis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:175\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    173\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output = train(target_model, growth_schedule, loss, loss_name, optimizer, train_loader, val_loader, num_epochs, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21af44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c23eee6",
   "metadata": {},
   "source": [
    "## Train & Grow the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6dadcfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_model = ANN(num_inputs, num_hidden, num_outputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "982ea8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "#loss = nn.CrossEntropyLoss()\n",
    "loss_name = \"MSE\" \n",
    "#loss_name = \"CE\"\n",
    "optimizer = torch.optim.Adam(root_model.parameters(), lr=1e-3)\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52cd2547",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 9\n",
    "growth_schedule = iter([[\"fc1\", num_neurons],[\"fc2\", num_neurons],[\"fc1\", num_neurons],\n",
    "                        [\"fc2\", num_neurons],[\"fc1\", num_neurons],[\"fc2\", num_neurons],\n",
    "                        [\"fc1\", num_neurons],[\"fc2\", num_neurons],[\"fc1\", num_neurons],\n",
    "                        [\"fc2\", num_neurons],[\"fc1\", num_neurons],[\"fc2\", num_neurons],\n",
    "                        [\"fc1\", num_neurons],[\"fc2\", num_neurons],[\"fc1\", num_neurons],\n",
    "                        [\"fc2\", num_neurons],[\"fc1\", num_neurons],[\"fc2\", num_neurons],\n",
    "                        [\"fc1\", num_neurons],[\"fc2\", num_neurons],[\"fc1\", num_neurons]])\n",
    "c = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "145c79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks_list= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aca4b926",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(100, device='cuda:0')\n",
      "50 batches used in epoch 0\n",
      "tensor(190, device='cuda:0')\n",
      "100 batches used in epoch 0\n",
      "tensor(280, device='cuda:0')\n",
      "150 batches used in epoch 0\n",
      "tensor(370, device='cuda:0')\n",
      "200 batches used in epoch 0\n",
      "tensor(460, device='cuda:0')\n",
      "250 batches used in epoch 0\n",
      "tensor(550, device='cuda:0')\n",
      "300 batches used in epoch 0\n",
      "tensor(640, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 1/3 [00:09<00:18,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(730, device='cuda:0')\n",
      "50 batches used in epoch 1\n",
      "tensor(820, device='cuda:0')\n",
      "100 batches used in epoch 1\n",
      "tensor(910, device='cuda:0')\n",
      "150 batches used in epoch 1\n",
      "tensor(1000, device='cuda:0')\n",
      "200 batches used in epoch 1\n",
      "tensor(1090, device='cuda:0')\n",
      "250 batches used in epoch 1\n",
      "tensor(1180, device='cuda:0')\n",
      "300 batches used in epoch 1\n",
      "tensor(1270, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:18<00:09,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1360, device='cuda:0')\n",
      "50 batches used in epoch 2\n",
      "tensor(1450, device='cuda:0')\n",
      "100 batches used in epoch 2\n",
      "tensor(1540, device='cuda:0')\n",
      "150 batches used in epoch 2\n",
      "tensor(1630, device='cuda:0')\n",
      "200 batches used in epoch 2\n",
      "tensor(1720, device='cuda:0')\n",
      "250 batches used in epoch 2\n",
      "tensor(1810, device='cuda:0')\n",
      "300 batches used in epoch 2\n",
      "tensor(1900, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.30s/it]\n"
     ]
    }
   ],
   "source": [
    "output = train(root_model, growth_schedule, loss, loss_name, optimizer, train_loader, val_loader, num_epochs, batch_size, device, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "70b52e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.019659467563941713,\n",
       "  0.03322672337384486,\n",
       "  0.045729304845558434,\n",
       "  0.0563097451813519,\n",
       "  0.06491421621928854,\n",
       "  0.07178669707940483,\n",
       "  0.004854535808923041,\n",
       "  0.008826362554029358,\n",
       "  0.012372124343883337,\n",
       "  0.015586675988033233,\n",
       "  0.018640646287921545,\n",
       "  0.021570300896334032,\n",
       "  0.002770292862295741,\n",
       "  0.005379031159597017,\n",
       "  0.007945245327768712,\n",
       "  0.010499694401670883,\n",
       "  0.013105801198767817,\n",
       "  0.015756988230661104],\n",
       " [11.72,\n",
       "  21.09,\n",
       "  47.66,\n",
       "  64.06,\n",
       "  69.53,\n",
       "  83.59,\n",
       "  82.03,\n",
       "  86.72,\n",
       "  83.59,\n",
       "  89.06,\n",
       "  88.28,\n",
       "  89.84,\n",
       "  89.06,\n",
       "  89.06,\n",
       "  90.62,\n",
       "  91.41,\n",
       "  91.41,\n",
       "  90.62],\n",
       " [0.09009817987680435,\n",
       "  0.08709118515253067,\n",
       "  0.07664433866739273,\n",
       "  0.06534033268690109,\n",
       "  0.05255601555109024,\n",
       "  0.04278464615345001,\n",
       "  0.03154897689819336,\n",
       "  0.028091518208384514,\n",
       "  0.026284297928214073,\n",
       "  0.02581351436674595,\n",
       "  0.026900852099061012,\n",
       "  0.023041391745209694,\n",
       "  0.02156229503452778,\n",
       "  0.022510869428515434,\n",
       "  0.02308960072696209,\n",
       "  0.024956492707133293,\n",
       "  0.020847737789154053,\n",
       "  0.023315871134400368],\n",
       " [11.72,\n",
       "  20.31,\n",
       "  39.06,\n",
       "  62.5,\n",
       "  68.75,\n",
       "  81.25,\n",
       "  82.81,\n",
       "  82.81,\n",
       "  84.38,\n",
       "  83.59,\n",
       "  84.38,\n",
       "  85.16,\n",
       "  85.94,\n",
       "  83.59,\n",
       "  84.38,\n",
       "  83.59,\n",
       "  88.28,\n",
       "  85.94]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e458590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2001bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2db2dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path + f\"\\\\SNN_LoRA/ICL5_state_dict_task_{1}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fe41c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deafff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c7d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3d62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
