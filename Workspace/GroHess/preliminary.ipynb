{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "data_path = os.path.join(path, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many computations to compute diagonal elements of the Hessian ?\n",
    "def compute_necessary (nx, n1, n2, ny) :\n",
    "    return n2*ny * (1 + n1 + nx*n1)\n",
    "\n",
    "def compute_total (nx, n1, n2, ny) :\n",
    "    return (nx*n1 + n1*n2 + n2*ny)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "ny = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary computations:  7.85e+07\n",
      "Total computations:  7.99e+09\n",
      "Ratio:  1.02e+02\n"
     ]
    }
   ],
   "source": [
    "print(\"Necessary computations: \", format(compute_necessary(nx, n1, n2, ny), \".2e\"))\n",
    "print(\"Total computations: \", format(compute_total(nx, n1, n2, ny), \".2e\"))\n",
    "print(\"Ratio: \", format(compute_total(nx, n1, n2, ny) / compute_necessary(nx, n1, n2, ny), \".2e\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get MNIST loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "def get_MNIST_loaders(path, class_names, batch_size, download=False) :\n",
    "\n",
    "    # load MNIST \n",
    "    mnist_train = datasets.MNIST(root=path, train=True, download=download, transform=MNIST_transform)\n",
    "    mnist_test = datasets.MNIST(root=path, train=False, download=download, transform=MNIST_transform)\n",
    "\n",
    "\n",
    "    # create a mask to filter indices for each label\n",
    "    train_mask = torch.tensor([label in class_names for label in mnist_train.targets])\n",
    "    test_mask = torch.tensor([label in class_names for label in mnist_test.targets])\n",
    "\n",
    "    # Create Subset datasets for train, validation, and test\n",
    "    train_dataset = Subset(mnist_train, torch.where(train_mask)[0])\n",
    "    test_dataset = Subset(mnist_test, torch.where(test_mask)[0])\n",
    "\n",
    "    # split train into train & validation\n",
    "    train_size = int(0.7 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_MNIST_loaders(data_path, range(10), batch_size, download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 784\n",
    "hidden_size = 100\n",
    "output_size = 10\n",
    "model = SimpleMLP(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute second derivative while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.3488340377807617\n",
      "Second derivative of parameter 0: tensor([[ 0.1917,  0.1606,  0.6367,  0.5450, -0.0316, -0.0256,  0.1467, -0.0575,\n",
      "         -0.0162, -0.2791],\n",
      "        [ 0.3343,  0.2063,  0.9759,  0.8171, -0.0315, -0.0665,  0.3384, -0.0335,\n",
      "          0.3485, -0.2396],\n",
      "        [ 0.4028, -0.1661,  0.0139, -0.1765,  0.1429,  0.0278, -0.1045, -0.3401,\n",
      "          0.3231,  1.0075],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.1126,  0.0144, -0.0685, -0.0149, -0.0290, -0.0138,  0.0501,  0.1138,\n",
      "          0.0394, -0.1757]], grad_fn=<TBackward0>)\n",
      "Second derivative of parameter 1: tensor([ 0.0693,  0.2881,  0.3353,  0.0000, -0.0356], grad_fn=<ViewBackward0>)\n",
      "Second derivative of parameter 2: tensor([[1.0449, 0.8003, 1.2290, 0.0000, 0.0243]], grad_fn=<TBackward0>)\n",
      "Second derivative of parameter 3: tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass to compute gradients\n",
    "    loss.backward(create_graph=True)\n",
    "    \n",
    "    # Compute second derivatives (diagonal of the Hessian)\n",
    "    second_derivatives = []\n",
    "    for param in model.parameters():\n",
    "        if param.grad is not None:\n",
    "            grad = param.grad\n",
    "            second_derivative = torch.autograd.grad(\n",
    "                grad,\n",
    "                param,\n",
    "                grad_outputs=torch.ones_like(grad),\n",
    "                retain_graph=True,\n",
    "                create_graph=True,\n",
    "            )[0]\n",
    "            second_derivatives.append(second_derivative)\n",
    "    \n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss and second derivatives for the first epoch for demonstration\n",
    "    if epoch == 8:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "        for i, sd in enumerate(second_derivatives):\n",
    "            print(f\"Second derivative of parameter {i}: {sd}\")\n",
    "\n",
    "# This example demonstrates the computation for one batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([5])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters() :\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
